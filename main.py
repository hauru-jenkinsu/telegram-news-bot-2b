import os
import time
import json
import logging
import re
import feedparser
import schedule
from telegram import Bot
from telegram.constants import ParseMode
from telegram.error import TelegramError
from dotenv import load_dotenv
from urllib.parse import urljoin

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
log_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'parser.log')
logging.basicConfig(
    filename=log_file,
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logging.getLogger().addHandler(logging.StreamHandler())

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TOKEN = os.getenv("TOKEN")
CHANNELS = os.getenv("CHANNELS", "").split(",")
ADMIN_CHAT_ID = os.getenv("ADMIN_CHAT_ID")

PROCESSED_LINKS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'processed_links.json')
REJECTED_NEWS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'rejected_news.json')

RSS_FEEDS = [
    {"name": "lenta.ru", "url": "https://lenta.ru/rss/news/", "fallback": "https://lenta.ru/rss/"},
    {"name": "vpk.name", "url": "https://vpk.name/rss/", "fallback": None},
    {"name": "ria.ru", "url": "https://ria.ru/export/rss2/index.xml", "fallback": "https://ria.ru/export/rss2/army/index.xml"},
    {"name": "rg.ru", "url": "https://rg.ru/xml/index.xml", "fallback": None},
    {"name": "tass.ru", "url": "https://tass.ru/rss/v2.xml?sections=MjQ%3D", "fallback": None}
]

KEYWORDS = [
    "—Å–≤–æ", "–≤—Å —Ä—Ñ", "—Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –≤–æ–π—Å–∫–∞", "—Ä–æ—Å—Å–∏–π—Å–∫–∏–µ —É—á–µ–Ω–∏—è", "—Ä–æ—Å—Å–∏–π—Å–∫–∞—è –∞—Ä–º–∏—è",
    "—Ä–æ—Å—Å–∏–π—Å–∫–æ–µ –≤–æ–æ—Ä—É–∂–µ–Ω–∏–µ", "—Ä–æ—Å—Å–∏–π—Å–∫–∞—è —Ç–µ—Ö–Ω–∏–∫–∞", "—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è", "–≤–æ–µ–Ω–Ω—ã–π",
    "–∞—Ä–º–∏—è", "—É—á–µ–Ω–∏—è", "–≤–æ–π—Å–∫–∞", "—Ç–µ—Ö–Ω–∏–∫–∞", "–æ–¥–∫–±", "–≤–æ–æ—Ä—É–∂–µ–Ω–∏–µ",
    "—Ç–∞–Ω–∫", "—Ñ–ª–æ—Ç", "—Ä–∞–∫–µ—Ç–∞", "–æ–±–æ—Ä–æ–Ω–∞", "–º–∏–Ω–æ–±–æ—Ä–æ–Ω—ã", "–±–µ–ª–æ—É—Å–æ–≤",
    "–≤–æ–æ—Ä—É–∂—ë–Ω–Ω—ã–µ —Å–∏–ª—ã", "–∫–æ–Ω—Ñ–ª–∏–∫—Ç", "–Ω–∞—ë–º–Ω–∏–∫", "–≤—Å—É"
]

bot = Bot(token=TOKEN)


def load_processed_links():
    try:
        with open(PROCESSED_LINKS_FILE, "r", encoding='utf-8') as f:
            return set(json.load(f))
    except FileNotFoundError:
        logging.info("–§–∞–π–ª processed_links.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π.")
        return set()


def save_processed_links(links):
    try:
        with open(PROCESSED_LINKS_FILE, "w", encoding='utf-8') as f:
            json.dump(list(links), f, ensure_ascii=False)
        logging.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(links)} —Å—Å—ã–ª–æ–∫")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ processed_links: {e}")


def save_rejected_news(title, link, reason):
    try:
        rejected = []
        if os.path.exists(REJECTED_NEWS_FILE):
            with open(REJECTED_NEWS_FILE, "r", encoding='utf-8') as f:
                rejected = json.load(f)
        rejected.append({
            "title": title,
            "link": link,
            "reason": reason,
            "time": time.strftime("%Y-%m-%d %H:%M:%S")
        })
        with open(REJECTED_NEWS_FILE, "w", encoding='utf-8') as f:
            json.dump(rejected, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏: {e}")


def matches_keywords(text):
    text = text.lower()
    for keyword in KEYWORDS:
        if re.search(r'\b' + re.escape(keyword.lower()) + r'\b', text):
            return True
    return False


def parse_feed(feed):
    try:
        parsed = feedparser.parse(feed["url"])
        if not parsed.entries and feed.get("fallback"):
            parsed = feedparser.parse(feed["fallback"])
        return parsed.entries[:5]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {feed['name']}: {e}")
        return []


async def publish_news(title, link):
    message = f"üì∞ <b>{title}</b>\nüîó {link}"
    if TEST_MODE:
        logging.info(f"[–¢–ï–°–¢] –ù–æ–≤–æ—Å—Ç—å –≥–æ—Ç–æ–≤–∞ –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ: {message}")
        print(f"[–¢–ï–°–¢] {message}")
        return True

    success = True

    for channel in CHANNELS:
        if not channel.strip():
            logging.warning("–ü—Ä–æ–ø—É—â–µ–Ω –ø—É—Å—Ç–æ–π chat_id –≤ —Å–ø–∏—Å–∫–µ CHANNELS")
            continue
        try:
            await bot.send_message(chat_id=channel.strip(), text=message, parse_mode=telegram.constants.ParseMode.HTML)
            await asyncio.sleep(2)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {channel}: {e}")
            success = False
            try:
                if ADMIN_CHAT_ID:
                    await bot.send_message(chat_id=ADMIN_CHAT_ID, text=f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {channel}: {e}")
            except Exception as e_admin:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞: {e_admin}")
    return success

def main():
    logging.info(f"–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    processed_links = load_processed_links()

    for feed in RSS_FEEDS:
        entries = parse_feed(feed)
        for entry in entries:
            title = entry.get("title", "").strip()
            link = entry.get("link", "").strip()
            desc = entry.get("summary", entry.get("description", "")).strip()

            if not title or not link:
                continue

            if link in processed_links:
                save_rejected_news(title, link, "–¥—É–±–ª–∏–∫–∞—Ç")
                continue

            if matches_keywords(title) or matches_keywords(desc):
                if publish_news(title, link):
                    processed_links.add(link)
                else:
                    save_rejected_news(title, link, "–æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏")
            else:
                save_rejected_news(title, link, "–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º")

    save_processed_links(processed_links)
    logging.info("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å–∫—Ä–∏–ø—Ç–∞")


# –ó–∞–ø—É—Å–∫ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
def run_scheduler():
    schedule.every(1).hours.do(main)
    while True:
        schedule.run_pending()
        time.sleep(60)


if __name__ == "__main__":
    main()  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ run_scheduler() –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã
